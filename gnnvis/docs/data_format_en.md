# Documents for Data Descriptions
## Dataset
1. Type: Folder

2. Description: This folder is used to store multiple files of a dataset. The folder name is the same as the dataset name and can also be treated as an ID, which must be unique because it will be part of the route path.

3. Generation Method: Generated by Python. When generating the entire project folder (usually a front-end project folder of a Vue project) in the Jupyter environment, store these dataset folders in the "public" folder at the root path.

4. Naming Convention: The original name of the dataset - the name of the training model - other information, all in lowercase English letters.

    > For example: cora-gcn-epoch50, mutag-mpnn-20230331

5. Each dataset should include the following files:

| No |                 File name | Description                                                                    |
|:--:|--------------------------:|:-------------------------------------------------------------------------------|
| 1  |                graph.json | ðŸ“Œ Necessary                                                                   |
| 2  |       node-embeddings.csv | ðŸ“Œ Necessary                                                                   |
| 3  |   prediction-results.json | ðŸ“Œ Necessary                                                                   |
| 4  |      graph-embeddings.csv | âœ… Optional (Multi-graph task only)                                             |
| 5  |       initial-layout.json | ðŸ“Œ Necessary                                                                   |
| 6  |            supplement.txt | âœ… Optional                                                                     |
| 7  |   graph-custom-index.json | âœ… Optional: user-defined index                                                 |
| 8  |   node-dense-features.csv | âœ… Optional: dense features of nodes                                            |
| 9  | node-sparse-features.json | âœ… Optional: sparse features of nodes                                           |
| 10 |           true-labels.txt | âœ… Optional (link-prediction & graph-classification only): true labels of nodes |


### 1. graph.json
1. Type: Json file, mainly referring to A.
2. Description: graph data.
3. Demo:

```json
{
    "directed": true/false,  // True if the graph is directed, false otherwise
    "multigraph": true/false,  // True if the graph has subgraphs, false otherwise
    "graphs": {  // multigraph only: Here saved information for each subgraph
        "0": {  // id of n subgarphs (from 0 to n-1, ascending order)
            "id": "0",
            "label": "",  // optional
            "nodes": [  // Array<int>
                0,1,5,17,29,33, //...
                // each integer represents the GLOBAL ID of a node in this subgraph
            ],
            "edges":[ // Array<int>
                0, 9, 50, 1190, //...
                // Just like "nodes", each integer represents the GLOBAL ID of an edge in this subgraph
                // if the whole graph is undirected, the edge represents two directions
            ]
        },
        "1": {
            // ...
        },
    },
    "nodes": [ // Array
        {   
            "id": 0, 
            "label": 8 // Optional: label of a node
        },
        //...    
    ],
    "edges": [
        {
            "source": 0,  // Starting point of edge
            "target": 1,  // End point of edge
            "eid": 0,     // id of the edge
            "label": 0    // Optional: label of the edge
        },
        //...
    ],
    "edgeDict": [  //2d-Array
        // The length is equal to the length of nodes,
        // for each node (indexed), it includes the directly connected edges and the first-order adjacent nodes.
        [ // The adjacent edges and nodes of node 0
          // Optional, the frontend will calculate them if not provided
            { "nid": 1, "eid": 0 }, // Node 0 is connected to Node 1 through Edge 0
            { "nid": 3, "eid": 1 }, // Node 0 is connected to Node 3 through Edge 1
            { "nid": 7, "eid": 2 }, // Node 0 is connected to Node 7 through Edge 2
            //...
        ],
        [ // The adjacent edges and nodes of node 1
        //...
    ],
}
```


### 2.node-embeddings.csv
1. Type: CSV file
2. Description: The training data of nodes in the embedding space is usually generated by the last layer of the MLP. Each line in the file represents the embedding data of a node, and the order of the nodes corresponds to the order of nodes in graph.json.

> Generally, they are arranged in ascending order of ID. The data in each line is separated by commas (with spaces allowed), and the last dimension does not have a comma. It does not include line numbers, node IDs, or any other data.

3. Demo: an example in a 5-dimensional space:

```csv
0.130,0.307,0.044,0.032,0.166
0.208,0.510,0.062,0.086,0.112
0.171,0.296,0.262,0.097,0.161
0.104,0.357,0.151,-0.125,0.278
0.374,0.109,-0.143,-0.171,-0.080
//...
```


### 3.prediction-results.json
1. Type: Json file
2. Description: The output of the model prediction. Three different tasks have different formats.

#### node-classification
```json
{
    "taskType": "node-classification",
    "numNodeClasses": 7,  // int: number of points' classes
    "predLabels": [  // Array<int>: predicted labels of nodes, the order is the same as the order of nodes in graph.json
        0, 1, 2, 3, 4, 5, 6,  //...
    ],
    "trueLabels": [  // Array<int>: true labels of nodes, the order is the same as the order of nodes in graph.json
        0, 0, 2, 3, 4, 5, 5,  //...
    ]
}
```

#### link-prediction
```json
{
    "taskType": "link-prediction",
    "trueAllowEdges": [  // Array<Array<int, int> >
        [0, 1],  // edge that exists in the original graph and is predicted correctly
        [0, 2],  // presented by [starting point ID, end point ID]
        //...
    ],
    "falseAllowEdges": [  // Array< <int, int> >
        [0, 18],  // edge that exists in the original graph but is not predicted
        [1, 39],  // presented by [starting point ID, end point ID]
        //...
    ],
    "trueUnseenTopK": 5,  // int: recommended edges that are not present in the original image are determined by a score sorting
                          // represents the top few selections.
    "trueUnseenEdgesSorted": {  // edges that do not exist in the original graph but are recommended by the model
        "11": [44, 161, 3, 19, 339],  // each KEY represents a node ID, and the corresbonding VALUE is an Array<int> with a length of "trueUnseenTopK"
        "16": [145, 122, 259, 321, 324],  // each int is a node ID, and the order of the edges is determined by the score
        //...
    }
}
```


#### graph-classification
```json
{
    "taskType": "graph-classification",
    "numGraphClasses": 7,  // int: number of graphs' classes
    "graphIndex": [  // Array<int> (Optional): index of each subgraph (the same as KEYs of "graphs" in graph.json)
    ],               // if not given, it represents 0~n-1 (ascending order)
    "predLabels": [  // Array: predicted labels of subgraphs (the order is the same as "graphs" in graph.json)
    ],
    "trueLabels": [  // Array: true labels of subgraphs (the order is the same as "graphs" in graph.json)
    ],
    "phaseDict": {  // Dict (Optional): different useage of graph participation in training
        0: "train",
        1: "valid",
        2: "predict"
    },
    "phase": [  // Array<int>: the useage of each subgraph
        1, 2, 0, 0, 0, 1, 1, 0,  //...
    ]
}
```

### 4.graph-embeddings.csv

1. Type: CSV file
2. Description: Graph-classification only. It represents the training data of each graph in the embedding space. Each line in the file represents the embedding data of a graph, and the order of the graphs corresponds to graph.json.
3. Demo: an example in a 5-dimensional space:

```csv
0.244,-0.146,0.252,-0.240,-0.302
-0.221,-0.431,0.214,0.153,0.007
0.147,-0.199,0.385,0.066,-0.250
0.110,0.171,-0.066,0.849,0.377
//...
```


### 5.initial-layout.json
1. Type: Json file
2. Description: Some computationally intensive initial rendering data, including the force-directed layout of graphs and the dimensionality reduction results of embedded spatial data.
3. Introduction to Calculation Methods:
    - forceDirectedLayout: https://github.com/d3/d3-force/tree/v3.0.0#d3-force
    - Umap, Tsne: can use "sklearn" library in python
4. Demo:

```json
{
    "forceDirectedLayout": [  // Array<Dict>: The length is equal to the length of the nodes, storing the coordinates of the points during the initial rendering of the graph.
        {"id":0, "x":23.1, "y":50.3 },  // corresponding to the id of each node
        {"id":1, "x":44.5, "y":90.1 },
        //...
    ],
    "nodeEmbUmp": [  // Array< <int, int> >: the same size of nodes. The data of node embeddings in the spatial dimension after being reduced by UMAP (two-dimensional).
       [1.334,5.132],
       //...
    ],
    "graphEmbUmp": [  // Array< <int, int> >: the same size of graphs. The data of graph embeddings in the spatial dimension after being reduced by UMAP (two-dimensional)
       [1.334,5.132],
       //...
    ]
}
```


### 6.supplement.txt
1. Type: txt file
2. Description: Any other information about this dataset, such as the hyperparameters of this training. Written manually, not generated by a program.



### 7.graph-custom-index.json
1. Type: Json file
2. Description: User defined feature calculated by "backend/custom_index.py"
3. Demo:

```json
{
    "index_target": "graph" | "node",  // Feature type
    "number_of_C": {  // user defined name of a feature
        "0": 14,  // KEY: subgraph or node ID, VALUE: feature value
        "1": 9,
        "2": 9,
        "3": 16,
        "4": 6,
        ...
     },
     "number_of_F": {
         ...
     },
     ...
}
```



### 8.node-dense-features.csv

1. Type: CSV file
2. Description: Dense features of nodes. Each node may have multiple features, but each feature is a scalar value. The first line is the name of the feature (optional). The following 2-n lines correspond to the number of nodes, and the values are the node features.
3. Demo:
4. 
```csv
feat-1,feat-2,feat-3
1.34,2.0,18.628
1.80,0.0,18.96
4.20,0.0,5.488
3.99,1.0,18.884
...
```


### 9.node-sparse-features.json

1. Type: Json file
2. Description: Sparse features of nodes
3. Demo:

```json
{
    "numNodeFeatureDims": 888,  // int: number of feature dimensions
    "nodeFeatureIndexes": [  // Array<Array<int> > Index order corresponds to node
                             // Indicates the indices (starting from zero) on which values are non-empty for the current node among multiple feature dimensions.
        [65, 77, 391, 801],  // Node 0 has data in dimensions 65, 77, 391, and 801 of the feature
        [30, 102, 887],      // Node 1 has data in dimensions 30, 102, and 887 of the feature
        ...
    ],
    "nodeFeatureValues":[  // Array<Array<int> > Index order corresponds to nodeFeatureIndexes
                           // feature values in corresponding dimensions
        [1.2, 1.5, 1.8, 0.3],  // Node 0 has a value of 1.2 on the 65th dimension of the feature, 1.5 on the 77th, etc.
        [0.2, 1.4, 1.5],       // Node 1 has a value of 0.2 on the 30th dimension of the feature, 1.4 on the 102nd, etc.
        ...
    ]
}
```


## Format of python object

Create a dataset file by calling as follows:
```python
GNNVis(
    graph,
    node_embed,
    node_dense_features,
    node_dense_features_name,
    node_sparse_features,
    link_pred_res,
    node_classify_res,
    graph_classify_res,
    graph_embed,
    gen_path,
)
```

The meanings of each parameter are as follows:

### graph
Python dict: the same as "graph.json"

### node_embed
(Optional) numpy.ndarray (2d)

### node_dense_features
(Optional) numpy.ndarray (2d)

### node_dense_features_name
(Optional) List: names of dense features of nodes

### node_sparse_features
(Optional) Python dict: the same as "node-sparse-features.json"


### link_pred_res
(Optional) Python dict: the same as "prediction-results.json"


### node_classify_res
(Optional) Python dict: the same as "prediction-results.json"

### graph_classify_res
(Optional) Python dict: the same as "prediction-results.json"


### graph_embed
(Optional) numpy.ndarray (2d)


### gen_path
(Optional) str: the path of the dataset folder (or the location of "backend")


